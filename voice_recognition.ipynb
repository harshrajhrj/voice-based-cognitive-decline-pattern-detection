{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGpZkNxy51Sa",
        "outputId": "69b3ecae-787d-4912-80a0-7d3dabac2432"
      },
      "outputs": [],
      "source": [
        "# !pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eNjAL5BB7EDO"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhiQBT9j7Cfb",
        "outputId": "6c55b44b-ffc4-4375-abd0-babf24e3fe05"
      },
      "outputs": [],
      "source": [
        "# drive.mount('/content/drive')\n",
        "\n",
        "# images = '/content/drive/MyDrive/Colab Notebooks/audio_samples/' # zip file path\n",
        "# ouput = '/content/dataset' # extracted dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hFgavu25e3s",
        "outputId": "68a6e9a9-3531-4f2e-e363-31591ba0576e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing audio files in: /content/drive/MyDrive/Colab Notebooks/audio_samples/\n",
            "\n",
            "File: voice_one.ogg\n",
            "Transcript: what's your name\n",
            "Features: {'speech_rate': array([170.45454545]), 'pitch_variability': np.float32(816.0424), 'duration': 1.6135, 'pause_rate': 0.0, 'word_per_sentence': 3.0, 'hesitation_count': 0}\n",
            "\n",
            "File: voice_two.ogg\n",
            "Transcript: hello everyone my name is harshad and I am from mtk today I'm going to leave a Road Plantation on topic energy efficient and LP so as per the growing models and it'll be doing best model are very low so as you can see\n",
            "Features: {'speech_rate': array([156.25]), 'pitch_variability': np.float32(950.50323), 'duration': 35.0335, 'pause_rate': 0.0, 'word_per_sentence': 15.0, 'hesitation_count': 0}\n",
            "\n",
            "File: voice_one.ogg.wav\n",
            "Transcript: what's your name\n",
            "Features: {'speech_rate': array([170.45454545]), 'pitch_variability': np.float32(888.43646), 'duration': 1.6135, 'pause_rate': 0.0, 'word_per_sentence': 3.0, 'hesitation_count': 0}\n",
            "\n",
            "File: voice_two.ogg.wav\n",
            "Transcript: hello everyone my name is harshad and I am from mtk today I'm going to leave a Road Plantation on topic energy efficient and LP so as per the growing models and it'll be doing best model are very low so as you can see\n",
            "Features: {'speech_rate': array([156.25]), 'pitch_variability': np.float32(969.18), 'duration': 34.976, 'pause_rate': 0.0, 'word_per_sentence': 15.0, 'hesitation_count': 0}\n",
            "voice_one.ogg - At Risk\n",
            "voice_two.ogg - Normal\n",
            "voice_one.ogg.wav - Normal\n",
            "voice_two.ogg.wav - Normal\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import speech_recognition as sr\n",
        "import spacy\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from pydub import AudioSegment\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# audio preprocessing & speech to text\n",
        "def preprocess_audio(audio_path, sr_target=16000):\n",
        "    y, sr = librosa.load(audio_path, sr=sr_target, mono=True)\n",
        "    y_trimmed, _ = librosa.effects.trim(y)\n",
        "    return y_trimmed, sr\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    # convert audio to WAV format if it's not already\n",
        "    if not audio_path.lower().endswith(('.wav', '.flac', '.aiff', '.aifc')):\n",
        "        try:\n",
        "            audio = AudioSegment.from_file(audio_path)\n",
        "            temp_audio_path = audio_path + '.wav'  # create a temporary WAV file\n",
        "            audio.export(temp_audio_path, format=\"wav\")\n",
        "            audio_path = temp_audio_path  # sse the temporary WAV file for transcription\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting audio file: {e}\")\n",
        "            return \"\"  # return empty string if conversion fails\n",
        "\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_path) as source:\n",
        "        audio = recognizer.record(source)\n",
        "    try:\n",
        "        text = recognizer.recognize_google(audio)\n",
        "    except sr.UnknownValueError:\n",
        "        text = \"\"\n",
        "\n",
        "    # removing the temporary WAV file if it was created\n",
        "    if audio_path.endswith('.wav') and audio_path != audio_path:\n",
        "        os.remove(audio_path)\n",
        "\n",
        "    return text\n",
        "\n",
        "# feature extraction\n",
        "def extract_audio_features(y, sr):\n",
        "    duration = librosa.get_duration(y=y, sr=sr)\n",
        "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
        "    pitch = pitches[magnitudes > np.median(magnitudes)]\n",
        "    pitch_std = np.std(pitch) if len(pitch) > 0 else 0\n",
        "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
        "    return {\n",
        "        \"speech_rate\": tempo,\n",
        "        \"pitch_variability\": pitch_std,\n",
        "        \"duration\": duration\n",
        "    }\n",
        "\n",
        "def extract_text_features(text):\n",
        "    doc = nlp(text)\n",
        "    num_sentences = len(list(doc.sents))\n",
        "    num_words = len([t for t in doc if t.is_alpha])\n",
        "    hesitations = sum(1 for word in text.lower().split() if word in [\"uh\", \"um\", \"like\"])\n",
        "    pause_rate = hesitations / num_sentences if num_sentences > 0 else 0\n",
        "    word_per_sentence = num_words / num_sentences if num_sentences > 0 else 0\n",
        "    return {\n",
        "        \"pause_rate\": pause_rate,\n",
        "        \"word_per_sentence\": word_per_sentence,\n",
        "        \"hesitation_count\": hesitations\n",
        "    }\n",
        "\n",
        "# unsupervised analysis #\n",
        "def detect_anomalies(features):\n",
        "    feature_matrix = np.array([[\n",
        "        f[\"speech_rate\"][0] if isinstance(f[\"speech_rate\"], np.ndarray) else f[\"speech_rate\"],  # access the first element if it's an array\n",
        "        f[\"pitch_variability\"],\n",
        "        f[\"pause_rate\"],\n",
        "        f[\"word_per_sentence\"]\n",
        "    ] for f in features])\n",
        "    model = IsolationForest(contamination=0.2)\n",
        "    anomalies = model.fit_predict(feature_matrix)\n",
        "    return anomalies\n",
        "\n",
        "# demo run #\n",
        "def analyze_audio_files(folder_path):\n",
        "    results = []\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith((\".wav\", \".ogg\")):\n",
        "            audio_path = os.path.join(folder_path, file)\n",
        "            y, sr = preprocess_audio(audio_path)\n",
        "            text = transcribe_audio(audio_path)\n",
        "            audio_feats = extract_audio_features(y, sr)\n",
        "            text_feats = extract_text_features(text)\n",
        "            all_feats = {**audio_feats, **text_feats, \"filename\": file, \"text\": text}\n",
        "            results.append(all_feats)\n",
        "    return results\n",
        "\n",
        "# risk scoring api #\n",
        "def get_cognitive_decline_risk_score(audio_path):\n",
        "    y, sr = preprocess_audio(audio_path)\n",
        "    text = transcribe_audio(audio_path)\n",
        "    audio_feats = extract_audio_features(y, sr)\n",
        "    text_feats = extract_text_features(text)\n",
        "    # simple scoring: normalized sum of key features\n",
        "    score = (\n",
        "        audio_feats[\"pitch_variability\"] * 0.3 +\n",
        "        text_feats[\"pause_rate\"] * 0.4 +\n",
        "        text_feats[\"hesitation_count\"] * 0.3\n",
        "    )\n",
        "    return min(score, 1.0)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    folder = './audio_samples/'  # path to the folder containing audio files\n",
        "    print(\"Analyzing audio files in:\", folder)\n",
        "    all_features = analyze_audio_files(folder)\n",
        "    for entry in all_features:\n",
        "        print(f\"\\nFile: {entry['filename']}\")\n",
        "        print(f\"Transcript: {entry['text']}\")\n",
        "        print(\"Features:\", {k: v for k, v in entry.items() if k not in [\"filename\", \"text\"]})\n",
        "\n",
        "    anomalies = detect_anomalies(all_features)\n",
        "    for i, entry in enumerate(all_features):\n",
        "        entry[\"anomaly\"] = anomalies[i]\n",
        "        print(f\"{entry['filename']} - {'At Risk' if anomalies[i] == -1 else 'Normal'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPxdCObI6Ebf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
